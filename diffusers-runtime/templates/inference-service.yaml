apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  annotations:
    serving.kserve.io/deploymentMode: RawDeployment
  name: diffusers-runtime
spec:
  predictor:
    containers:
      - name: kserve-container
        image: quay.io/cfchase/diffusers-runtime:latest
        imagePullPolicy: Always
        resources:
          limits:
            cpu: '14'
            memory: 24Gi
            nvidia.com/gpu: 1
          requests:
            cpu: '4'
            memory: 8Gi
            nvidia.com/gpu: 1
        env:
          - name: MODEL_ID
            value: 'stabilityai/stable-diffusion-2-1'
    tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule

