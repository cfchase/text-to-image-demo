{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning: Teaching AI About Your Specific Data\n",
    "\n",
    "In the previous notebook, we discovered that pre-trained models don't know about specific subjects. Now we'll solve this using **Dreambooth**, a technique for teaching Stable Diffusion about new concepts while preserving its general capabilities.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Dreambooth Technique** - How to fine-tune diffusion models effectively\n",
    "2. **Data Preparation** - Organizing training images for best results\n",
    "3. **Training Configuration** - Optimizing parameters for GPU resources\n",
    "4. **Model Persistence** - Saving to S3 for pipeline automation and serving\n",
    "\n",
    "## Why Fine-Tuning Matters in Production\n",
    "- **Personalization**: Adapt models to your specific domain\n",
    "- **Brand Consistency**: Generate content matching your style guides\n",
    "- **Proprietary Knowledge**: Teach models about your unique products/concepts\n",
    "- **Quality Control**: Improve accuracy for your use cases\n",
    "\n",
    "Let's teach our model to recognize and generate images of Teddy!\n",
    "\n",
    "![redhat dog](https://rhods-public.s3.amazonaws.com/sample-data/images/redhat-dog-small.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Memory Requirements\n",
    "\n",
    "**Important**: Fine-tuning requires significant GPU memory (24GB+). \n",
    "- **Recommended**: Shut down other notebook kernels to free memory\n",
    "- **Check GPU**: We need most of the GPU memory available\n",
    "- **Alternative**: Use the pipeline version for automated resource management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XU7NuMAA2drw",
    "outputId": "2e5ad228-fdf6-4828-e558-8c8c323ffdad",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A10G, 23028 MiB, 22503 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnTMyW41cC1E",
    "tags": []
   },
   "source": [
    "## Install Requirements\n",
    "\n",
    "**Note**: We're installing diffusers from source to get the latest training script compatibility. After installation, you may need to restart the kernel for the changes to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements-base.txt (line 13))\n",
      "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-humuvlfd\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-humuvlfd\n",
      "  Resolved https://github.com/huggingface/diffusers.git to commit 9d313fc718c8ace9a35f07dad9d5ce8018f8d216\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: boto3==1.37.38 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 1)) (1.37.38)\n",
      "Requirement already satisfied: botocore==1.37.38 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 2)) (1.37.38)\n",
      "Requirement already satisfied: grpcio==1.73.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 3)) (1.73.0)\n",
      "Requirement already satisfied: pandas==2.2.3 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 6)) (2.6.0+cu126)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 7)) (0.21.0+cu126)\n",
      "Requirement already satisfied: numpy==2.2.6 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 8)) (2.2.6)\n",
      "Requirement already satisfied: transformers==4.54.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 9)) (4.54.0)\n",
      "Requirement already satisfied: accelerate==1.9.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 10)) (1.9.0)\n",
      "Requirement already satisfied: ftfy==6.3.1 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 11)) (6.3.1)\n",
      "Requirement already satisfied: huggingface-hub==0.34.3 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 14)) (0.34.3)\n",
      "Requirement already satisfied: sentencepiece==0.2.0 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-base.txt (line 15)) (0.2.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/app-root/lib64/python3.11/site-packages (from boto3==1.37.38->-r requirements-base.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/app-root/lib64/python3.11/site-packages (from boto3==1.37.38->-r requirements-base.txt (line 1)) (0.11.5)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/app-root/lib64/python3.11/site-packages (from botocore==1.37.38->-r requirements-base.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/app-root/lib64/python3.11/site-packages (from botocore==1.37.38->-r requirements-base.txt (line 2)) (1.26.20)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.2.3->-r requirements-base.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.11/site-packages (from pandas==2.2.3->-r requirements-base.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/app-root/lib64/python3.11/site-packages (from torch==2.6.0->-r requirements-base.txt (line 6)) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/app-root/lib64/python3.11/site-packages (from torchvision==0.21.0->-r requirements-base.txt (line 7)) (11.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (2025.7.31)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib64/python3.11/site-packages (from transformers==4.54.0->-r requirements-base.txt (line 9)) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.11/site-packages (from accelerate==1.9.0->-r requirements-base.txt (line 10)) (5.9.8)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib64/python3.11/site-packages (from ftfy==6.3.1->-r requirements-base.txt (line 11)) (0.2.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/app-root/lib64/python3.11/site-packages (from huggingface-hub==0.34.3->-r requirements-base.txt (line 14)) (1.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy==1.13.1->torch==2.6.0->-r requirements-base.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: importlib_metadata in /opt/app-root/lib64/python3.11/site-packages (from diffusers==0.35.0.dev0->-r requirements-base.txt (line 13)) (8.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.37.38->-r requirements-base.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/app-root/lib64/python3.11/site-packages (from importlib_metadata->diffusers==0.35.0.dev0->-r requirements-base.txt (line 13)) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch==2.6.0->-r requirements-base.txt (line 6)) (2.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements-base.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements-base.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib64/python3.11/site-packages (from requests->transformers==4.54.0->-r requirements-base.txt (line 9)) (2025.6.15)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: flash-attn==2.8.2 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-gpu.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: bitsandbytes==0.46.1 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-gpu.txt (line 2)) (0.46.1)\n",
      "Requirement already satisfied: xformers==0.0.29.post2 in /opt/app-root/lib64/python3.11/site-packages (from -r requirements-gpu.txt (line 3)) (0.0.29.post2)\n",
      "Requirement already satisfied: torch in /opt/app-root/lib64/python3.11/site-packages (from flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (2.6.0+cu126)\n",
      "Requirement already satisfied: einops in /opt/app-root/lib64/python3.11/site-packages (from flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.11/site-packages (from bitsandbytes==0.46.1->-r requirements-gpu.txt (line 2)) (2.2.6)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (12.6.85)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/app-root/lib64/python3.11/site-packages (from torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.11/site-packages (from sympy==1.13.1->torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.11/site-packages (from jinja2->torch->flash-attn==2.8.2->-r requirements-gpu.txt (line 1)) (2.1.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements-base.txt\n",
    "!pip install -r requirements-gpu.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accelerate                1.9.0\n",
      "boto3                     1.37.38\n",
      "botocore                  1.37.38\n",
      "diffusers                 0.35.0.dev0\n",
      "ftfy                      6.3.1\n",
      "grpcio                    1.73.0\n",
      "pandas                    2.2.3\n",
      "protobuf                  4.25.8\n",
      "torch                     2.6.0+cu126\n",
      "torchvision               0.21.0+cu126\n",
      "transformers              4.54.0\n",
      "xformers                  0.0.29.post2\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep -E \"boto|grpcio|pandas|torch|torchvision|diffusers|transformers|accelerate|flash-attn|ftfy|xformers|protobuf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important**: If you see an older version of diffusers (like 0.34.0) instead of a development version (e.g., 0.35.0.dev0), you need to restart the kernel for the source installation to take effect:\n",
    "1. Kernel → Restart Kernel\n",
    "2. Re-run the cells from the beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0NV324ZcL9L"
   },
   "source": [
    "## Training Configuration\n",
    "\n",
    "Configure all training parameters using environment variables. This approach enables:\n",
    "- Parameterized notebooks for different experiments\n",
    "- Integration with pipelines using different settings\n",
    "- Keeping sensitive information out of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using HF_TOKEN from environment variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# Check if HF_TOKEN environment variable is set\n",
    "if not os.environ.get('HF_TOKEN'):\n",
    "    print(\"HF_TOKEN environment variable not found.\")\n",
    "    print(\"Please log in to Hugging Face to access models.\")\n",
    "    login()\n",
    "else:\n",
    "    print(\"Using HF_TOKEN from environment variable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Integration\n",
    "\n",
    "We authenticate with Hugging Face to:\n",
    "- Download the base model for fine-tuning\n",
    "- Access gated models that require agreement to terms\n",
    "- (Optional) Upload our fine-tuned model back to Hugging Face\n",
    "\n",
    "This integration shows how OpenShift AI workbenches can securely connect to external services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxg0y5MBudmd",
    "outputId": "1c67fe1f-5652-439c-abae-920824533765",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights will be saved at /opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog\n",
      "It will be based on the model stabilityai/stable-diffusion-3.5-medium\n",
      "Training data located in downloaded from https://rhods-public.s3.amazonaws.com/sample-data/images/redhat-dog.tar.gz\n",
      "We're going to train the difference between \"photo of a rhteddy dog\" and \"a photo of dog\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.now()\n",
    "date_string = date.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "VERSION = os.environ.get(\"VERSION\", f\"notebook-output\")\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\", \"stabilityai/stable-diffusion-3.5-medium\")\n",
    "OUTPUT_DIR = os.path.join(os.getcwd(), f\"{VERSION}/stable_diffusion_weights/redhat-dog\")\n",
    "DATA_DIR = os.path.join(os.getcwd(), f\"{VERSION}/data\")\n",
    "INSTANCE_DATA_URL = os.environ.get(\"INSTANCE_DATA_URL\", \"https://rhods-public.s3.amazonaws.com/sample-data/images/redhat-dog.tar.gz\")\n",
    "INSTANCE_DIR = os.path.join(DATA_DIR, \"instance_dir\")\n",
    "CLASS_DIR = os.path.join(DATA_DIR, \"class_dir\")\n",
    "INSTANCE_PROMPT = os.environ.get(\"INSTANCE_PROMPT\", \"photo of a rhteddy dog\")\n",
    "CLASS_PROMPT = os.environ.get(\"CLASS_PROMPT\", \"a photo of dog\")\n",
    "\n",
    "NUM_CLASS_IMAGES = int(os.environ.get(\"NUM_CLASS_IMAGES\", \"200\"))\n",
    "MAX_TRAIN_STEPS = int(os.environ.get(\"MAX_TRAIN_STEPS\", \"800\"))\n",
    "\n",
    "S3_PREFIX = f\"models/{VERSION}/redhat-dog\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(INSTANCE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Weights will be saved at {OUTPUT_DIR}\")\n",
    "print(f\"It will be based on the model {MODEL_NAME}\")\n",
    "print(f\"Training data located in downloaded from {INSTANCE_DATA_URL}\")\n",
    "print(f\"We're going to train the difference between \\\"{INSTANCE_PROMPT}\\\" and \\\"{CLASS_PROMPT}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Training Parameters Explained\n",
    "\n",
    "- **MODEL_NAME**: Base model to fine-tune (we use SD 3.5 Medium for quality)\n",
    "- **VERSION**: Helps organize experiments and model versions\n",
    "- **INSTANCE_PROMPT**: The new concept we're teaching (\"photo of a rhteddy dog\")\n",
    "- **CLASS_PROMPT**: The general category to preserve (\"a photo of dog\")\n",
    "- **NUM_CLASS_IMAGES**: Regularization images to prevent overfitting\n",
    "- **MAX_TRAIN_STEPS**: Training duration (800 steps ≈ 15 minutes on A10G)\n",
    "\n",
    "The Dreambooth technique uses these prompts to:\n",
    "1. Learn the specific subject (instance)\n",
    "2. Preserve general knowledge (class)\n",
    "3. Enable prompts like \"rhteddy dog in the snow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qn5ILIyDJIcX"
   },
   "source": [
    "## Training Workflow\n",
    "\n",
    "The training process involves:\n",
    "1. **Data Preparation** - Download and organize training images\n",
    "2. **Model Configuration** - Set up the training environment\n",
    "3. **Training Execution** - Fine-tune the model\n",
    "4. **Model Persistence** - Save to S3 for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Prepare Training Data\n",
    "\n",
    "For Dreambooth, we need:\n",
    "- **5-10 images** of our subject (Teddy) from different angles\n",
    "- **Consistent quality** - Similar resolution and lighting\n",
    "- **Clear subject** - Teddy should be prominent in each image\n",
    "\n",
    "The images are stored in S3 and downloaded on-demand, demonstrating OpenShift AI's integration with object storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "\n",
    "url = INSTANCE_DATA_URL\n",
    "output = f\"instance-images.tar.gz\"\n",
    "urllib.request.urlretrieve(url, output)\n",
    "\n",
    "!tar -xzf instance-images.tar.gz -C $INSTANCE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Configure Accelerate\n",
    "\n",
    "[Accelerate](https://huggingface.co/docs/accelerate) handles distributed training configuration. For our single-GPU setup, we use the default configuration. In production, you might:\n",
    "- Use multiple GPUs for faster training\n",
    "- Configure mixed-precision training for efficiency\n",
    "- Set up distributed training across nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /opt/app-root/src/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    }
   ],
   "source": [
    "!accelerate config default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-07-30 19:52:59--  https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_sd3.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 74041 (72K) [text/plain]\n",
      "Saving to: ‘train_dreambooth_sd3.py’\n",
      "\n",
      "train_dreambooth_sd 100%[===================>]  72.31K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2025-07-30 19:52:59 (23.4 MB/s) - ‘train_dreambooth_sd3.py’ saved [74041/74041]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O train_dreambooth_sd3.py https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth_sd3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Download Training Script\n",
    "\n",
    "Download the Dreambooth SD3 training script from Hugging Face:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training\n",
    "\n",
    "Here we kick off the training job with our chosen settings.  This will take about 15 minutes depending on settings and hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Start Training\n",
    "\n",
    "Now we launch the training job. Key optimizations for GPU efficiency:\n",
    "- **Gradient checkpointing**: Trades computation for memory\n",
    "- **8-bit Adam**: Reduces optimizer memory usage\n",
    "- **xFormers**: Efficient attention implementation\n",
    "- **Prior preservation**: Maintains model's general capabilities\n",
    "\n",
    "**Expected duration**: ~15 minutes on an A10G GPU\n",
    "\n",
    "The training script will:\n",
    "1. Load the base model\n",
    "2. Generate regularization images\n",
    "3. Fine-tune on Teddy images\n",
    "4. Save checkpoints periodically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": "!accelerate launch train_dreambooth_sd3.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME  \\\n  --instance_data_dir=$INSTANCE_DIR \\\n  --class_data_dir=$CLASS_DIR \\\n  --output_dir=$OUTPUT_DIR \\\n  --with_prior_preservation --prior_loss_weight=1.0 \\\n  --instance_prompt=\"$INSTANCE_PROMPT\" \\\n  --class_prompt=\"$CLASS_PROMPT\" \\\n  --resolution=512 \\\n  --train_batch_size=1 \\\n  --gradient_checkpointing \\\n  --gradient_accumulation_steps=2 \\\n  --use_8bit_adam \\\n  --learning_rate=5e-6 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0 \\\n  --num_class_images=$NUM_CLASS_IMAGES \\\n  --max_train_steps=$MAX_TRAIN_STEPS"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training Results\n",
    "\n",
    "After training completes, we have:\n",
    "- **Model weights** for all components (UNet, VAE, text encoder)\n",
    "- **Tokenizer** with our new concept\n",
    "- **Configuration files** for easy loading\n",
    "\n",
    "These artifacts are ready for:\n",
    "1. Local testing in notebooks\n",
    "2. Upload to model registries (Hugging Face, S3)\n",
    "3. Deployment via KServe\n",
    "4. Pipeline automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-500\t   logs\t\t     scheduler\t   tokenizer  vae\n",
      "feature_extractor  model_index.json  text_encoder  unet\n"
     ]
    }
   ],
   "source": [
    "!ls $OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save to S3: Model Persistence\n",
    "\n",
    "Save the fine-tuned model to S3 storage for:\n",
    "- **Version Control**: Track model iterations\n",
    "- **Pipeline Integration**: Access models from any pipeline step\n",
    "- **Model Serving**: Deploy directly from S3\n",
    "- **Collaboration**: Share models across teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to S3\n",
    "\n",
    "Now we have our model in a portable ONNX format, however, it's not doing much good in this notebook. We need to push the model to our connected storage location. Then we can use it in another notebook or serve the models for use within an application.\n",
    "Note: This requires a data connection to an S3 compatible bucket. As part of the setup for this project, you added the setup-s3.yaml which created a local s3 bucket and data connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Integration in OpenShift AI\n",
    "\n",
    "The boto3 code below uses credentials from the Data Connection we attached to our workbench. OpenShift AI automatically:\n",
    "- Injects S3 credentials as environment variables\n",
    "- Configures endpoints for your storage provider  \n",
    "- Handles secure credential management\n",
    "\n",
    "This same pattern works with any S3-compatible storage:\n",
    "- Red Hat OpenShift Data Foundation\n",
    "- AWS S3\n",
    "- MinIO\n",
    "- IBM Cloud Object Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "aws_access_key_id = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "aws_secret_access_key = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "endpoint_url = os.environ.get('AWS_S3_ENDPOINT')\n",
    "region_name = os.environ.get('AWS_DEFAULT_REGION')\n",
    "bucket_name = os.environ.get('AWS_S3_BUCKET')\n",
    "\n",
    "session = boto3.session.Session(aws_access_key_id=aws_access_key_id,\n",
    "                                aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "s3_resource = session.resource(\n",
    "    's3',\n",
    "    config=botocore.client.Config(signature_version='s3v4'),\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=region_name)\n",
    "\n",
    "bucket = s3_resource.Bucket(bucket_name)\n",
    "\n",
    "\n",
    "def upload_directory_to_s3(local_directory, s3_prefix):\n",
    "    for root, dirs, files in os.walk(local_directory):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            relative_path = os.path.relpath(file_path, local_directory)\n",
    "            s3_key = os.path.join(s3_prefix, relative_path)\n",
    "            print(f\"{file_path} -> {s3_key}\")\n",
    "            bucket.upload_file(file_path, s3_key)\n",
    "\n",
    "\n",
    "def list_objects(prefix):\n",
    "    filter = bucket.objects.filter(Prefix=prefix)\n",
    "    for obj in filter.all():\n",
    "        print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your S3 path is models/notebook-output/redhat-dog\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your S3 path is {S3_PREFIX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/model_index.json -> models/notebook-output/redhat-dog/model_index.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/unet/config.json -> models/notebook-output/redhat-dog/unet/config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/unet/diffusion_pytorch_model.safetensors -> models/notebook-output/redhat-dog/unet/diffusion_pytorch_model.safetensors\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/scheduler/scheduler_config.json -> models/notebook-output/redhat-dog/scheduler/scheduler_config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/feature_extractor/preprocessor_config.json -> models/notebook-output/redhat-dog/feature_extractor/preprocessor_config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/events.out.tfevents.1753885701.pytorch-0.530.0 -> models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753885701.pytorch-0.530.0\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/events.out.tfevents.1753888714.pytorch-0.3239.0 -> models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753888714.pytorch-0.3239.0\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/events.out.tfevents.1753883079.pytorch-0.980.0 -> models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753883079.pytorch-0.980.0\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753888714.082692/hparams.yml -> models/notebook-output/redhat-dog/logs/dreambooth/1753888714.082692/hparams.yml\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753885701.586091/events.out.tfevents.1753885701.pytorch-0.530.1 -> models/notebook-output/redhat-dog/logs/dreambooth/1753885701.586091/events.out.tfevents.1753885701.pytorch-0.530.1\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753888714.0810964/events.out.tfevents.1753888714.pytorch-0.3239.1 -> models/notebook-output/redhat-dog/logs/dreambooth/1753888714.0810964/events.out.tfevents.1753888714.pytorch-0.3239.1\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753883079.0469809/events.out.tfevents.1753883079.pytorch-0.980.1 -> models/notebook-output/redhat-dog/logs/dreambooth/1753883079.0469809/events.out.tfevents.1753883079.pytorch-0.980.1\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753885701.5875413/hparams.yml -> models/notebook-output/redhat-dog/logs/dreambooth/1753885701.5875413/hparams.yml\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/logs/dreambooth/1753883079.0486026/hparams.yml -> models/notebook-output/redhat-dog/logs/dreambooth/1753883079.0486026/hparams.yml\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/text_encoder/config.json -> models/notebook-output/redhat-dog/text_encoder/config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/text_encoder/model.safetensors -> models/notebook-output/redhat-dog/text_encoder/model.safetensors\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/tokenizer/merges.txt -> models/notebook-output/redhat-dog/tokenizer/merges.txt\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/tokenizer/vocab.json -> models/notebook-output/redhat-dog/tokenizer/vocab.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/tokenizer/special_tokens_map.json -> models/notebook-output/redhat-dog/tokenizer/special_tokens_map.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/tokenizer/tokenizer_config.json -> models/notebook-output/redhat-dog/tokenizer/tokenizer_config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/checkpoint-500/optimizer.bin -> models/notebook-output/redhat-dog/checkpoint-500/optimizer.bin\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/checkpoint-500/random_states_0.pkl -> models/notebook-output/redhat-dog/checkpoint-500/random_states_0.pkl\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/checkpoint-500/scheduler.bin -> models/notebook-output/redhat-dog/checkpoint-500/scheduler.bin\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/checkpoint-500/unet/config.json -> models/notebook-output/redhat-dog/checkpoint-500/unet/config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/checkpoint-500/unet/diffusion_pytorch_model.safetensors -> models/notebook-output/redhat-dog/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/vae/config.json -> models/notebook-output/redhat-dog/vae/config.json\n",
      "/opt/app-root/src/text-to-image-demo/notebook-output/stable_diffusion_weights/redhat-dog/vae/diffusion_pytorch_model.safetensors -> models/notebook-output/redhat-dog/vae/diffusion_pytorch_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(OUTPUT_DIR, S3_PREFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/notebook-output/redhat-dog/checkpoint-500/optimizer.bin\n",
      "models/notebook-output/redhat-dog/checkpoint-500/random_states_0.pkl\n",
      "models/notebook-output/redhat-dog/checkpoint-500/scheduler.bin\n",
      "models/notebook-output/redhat-dog/checkpoint-500/unet/config.json\n",
      "models/notebook-output/redhat-dog/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
      "models/notebook-output/redhat-dog/feature_extractor/preprocessor_config.json\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753883079.0469809/events.out.tfevents.1753883079.pytorch-0.980.1\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753883079.0486026/hparams.yml\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753885701.586091/events.out.tfevents.1753885701.pytorch-0.530.1\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753885701.5875413/hparams.yml\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753888714.0810964/events.out.tfevents.1753888714.pytorch-0.3239.1\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/1753888714.082692/hparams.yml\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753883079.pytorch-0.980.0\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753885701.pytorch-0.530.0\n",
      "models/notebook-output/redhat-dog/logs/dreambooth/events.out.tfevents.1753888714.pytorch-0.3239.0\n",
      "models/notebook-output/redhat-dog/model_index.json\n",
      "models/notebook-output/redhat-dog/scheduler/scheduler_config.json\n",
      "models/notebook-output/redhat-dog/text_encoder/config.json\n",
      "models/notebook-output/redhat-dog/text_encoder/model.safetensors\n",
      "models/notebook-output/redhat-dog/tokenizer/merges.txt\n",
      "models/notebook-output/redhat-dog/tokenizer/special_tokens_map.json\n",
      "models/notebook-output/redhat-dog/tokenizer/tokenizer_config.json\n",
      "models/notebook-output/redhat-dog/tokenizer/vocab.json\n",
      "models/notebook-output/redhat-dog/unet/config.json\n",
      "models/notebook-output/redhat-dog/unet/diffusion_pytorch_model.safetensors\n",
      "models/notebook-output/redhat-dog/vae/config.json\n",
      "models/notebook-output/redhat-dog/vae/diffusion_pytorch_model.safetensors\n"
     ]
    }
   ],
   "source": [
    "list_objects(S3_PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model Storage Location\n",
    "\n",
    "Note the S3 prefix where your model is stored:\n",
    "- Format: `models/{VERSION}/redhat-dog/`\n",
    "- Example: `models/notebook-output/redhat-dog/`\n",
    "\n",
    "You'll need this path for:\n",
    "- Creating model servers in OpenShift AI\n",
    "- Referencing in pipelines\n",
    "- Sharing with team members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Congratulations! You've successfully:\n",
    "1. ✅ Fine-tuned a Stable Diffusion model on custom data\n",
    "2. ✅ Saved the model to S3 for persistence\n",
    "3. ✅ Prepared for pipeline automation and serving\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "1. **Create a Pipeline** (Optional)\n",
    "   - Convert this notebook to a repeatable pipeline\n",
    "   - Experiment with different parameters\n",
    "   - Train on multiple subjects\n",
    "\n",
    "2. **Deploy for Serving** \n",
    "   - Use the custom Diffusers runtime\n",
    "   - Create a KServe inference service\n",
    "   - Expose as REST API\n",
    "\n",
    "3. **Test the Deployment**\n",
    "   - Continue to [Notebook 3 - Remote Inference](3_remote_inference.ipynb)\n",
    "   - Test your model via REST API\n",
    "   - Integrate with applications\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Dreambooth** enables fine-tuning with minimal data (5-10 images)\n",
    "- **OpenShift AI** provides GPU resources and S3 integration\n",
    "- **Environment variables** enable parameterization for pipelines\n",
    "- **S3 storage** enables model versioning and serving\n",
    "\n",
    "Before proceeding, ensure you've noted your model's S3 path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your S3 path is models/notebook-output/redhat-dog\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your S3 path is {S3_PREFIX}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0cee055de82f4a4d8019e90d5ed1dfbb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "180888618e5a4d5d9c5bace5ef15c21a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da70b684ad3f44789cf0f213708f5da5",
      "placeholder": "​",
      "style": "IPY_MODEL_83954ef920464529acf6015cb9d31693",
      "value": "100%"
     }
    },
    "195e8f3e983342d9b7227ee9e4461153": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1d7ea19cc56a43c68df69bcc9655b8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a58f6b987c9f4f5e9a1b0a73c4ae549e",
       "IPY_MODEL_d2740a085b95416b88fa742e058402be",
       "IPY_MODEL_8252ddb68924432b87a1083b7e6aaa6e"
      ],
      "layout": "IPY_MODEL_e7113dfd596d4ecc8b1ebd76ee979d92"
     }
    },
    "28491b57195048b99c3714b60c8a25c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "582d3b3efd32478da7754bf2cb5530c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28491b57195048b99c3714b60c8a25c2",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b662d5f27cd5413db237b78bd137cae7",
      "value": 200
     }
    },
    "6eacdf7c06d041218c0b96745106e712": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "746ae93e85b94b0c9371e1dff99fc620": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8252ddb68924432b87a1083b7e6aaa6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe3f23ff7b8b46938a53c5e1bfdbaaca",
      "placeholder": "​",
      "style": "IPY_MODEL_916a795f943e475cbdc41ed25dab3deb",
      "value": " 200/200 [00:31&lt;00:00,  6.29it/s]"
     }
    },
    "83954ef920464529acf6015cb9d31693": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "916a795f943e475cbdc41ed25dab3deb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b8392f2d04e476ea94e7c5889d9fdd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58f6b987c9f4f5e9a1b0a73c4ae549e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be1ef96102b545a782d54b3dfd698696",
      "placeholder": "​",
      "style": "IPY_MODEL_746ae93e85b94b0c9371e1dff99fc620",
      "value": "100%"
     }
    },
    "b662d5f27cd5413db237b78bd137cae7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b9f236f54bf640f791c17beb11c95c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b8392f2d04e476ea94e7c5889d9fdd7",
      "placeholder": "​",
      "style": "IPY_MODEL_e3116fa65f6b4abcbc9ce7e61bdfb45f",
      "value": " 200/200 [00:31&lt;00:00,  6.34it/s]"
     }
    },
    "be1ef96102b545a782d54b3dfd698696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2740a085b95416b88fa742e058402be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eacdf7c06d041218c0b96745106e712",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_195e8f3e983342d9b7227ee9e4461153",
      "value": 200
     }
    },
    "da70b684ad3f44789cf0f213708f5da5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3116fa65f6b4abcbc9ce7e61bdfb45f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7113dfd596d4ecc8b1ebd76ee979d92": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eca04bb8e40f49c7869f00512e0767a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_180888618e5a4d5d9c5bace5ef15c21a",
       "IPY_MODEL_582d3b3efd32478da7754bf2cb5530c3",
       "IPY_MODEL_b9f236f54bf640f791c17beb11c95c66"
      ],
      "layout": "IPY_MODEL_0cee055de82f4a4d8019e90d5ed1dfbb"
     }
    },
    "fe3f23ff7b8b46938a53c5e1bfdbaaca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}